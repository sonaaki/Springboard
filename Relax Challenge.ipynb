{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64408b54",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Understanding and predicting user adoption is critical for the growth and retention of any digital product. In this project, we explore the user behavior patterns that lead to successful engagement, defined as a user logging into the product on **three separate days within a rolling seven-day period** — a common benchmark for early product adoption.\n",
    "\n",
    "We are provided with two datasets:\n",
    "1. **User Metadata (`takehome_users`)** — containing account creation details, sign-up methods, organizational information, and marketing preferences for ~12,000 users.\n",
    "2. **User Engagement (`takehome_user_engagement`)** — capturing individual login timestamps for users across time.\n",
    "\n",
    "The primary goal of this project is to:\n",
    "- Identify which users can be classified as “adopted” based on login activity.\n",
    "- Engineer relevant features from the user metadata.\n",
    "- Build a predictive model to uncover which characteristics are most closely associated with user adoption.\n",
    "\n",
    "By doing so, we aim to provide insights that can guide **product onboarding strategies, marketing efforts**, and **user experience improvements** — ultimately helping the business better engage new users and boost long-term retention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af17cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "users = pd.read_csv('takehome_users.csv', encoding='latin-1')\n",
    "engagement = pd.read_csv('takehome_user_engagement.csv', parse_dates=['time_stamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f6152",
   "metadata": {},
   "source": [
    "### Define \"Adopted Users\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbea69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates of logins on the same day per user\n",
    "engagement['login_date'] = engagement['time_stamp'].dt.date\n",
    "unique_logins = engagement[['user_id', 'login_date']].drop_duplicates()\n",
    "unique_logins = unique_logins.sort_values(by=['user_id', 'login_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efdb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify adopted users\n",
    "adopted_users = set()\n",
    "\n",
    "for user_id, group in unique_logins.groupby('user_id'):\n",
    "    dates = pd.Series(group['login_date'].tolist())\n",
    "    for i in range(len(dates) - 2):\n",
    "        if (dates[i+2] - dates[i]).days <= 7:\n",
    "            adopted_users.add(user_id)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6d6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Adopted Users in the User Table\n",
    "users['is_adopted'] = users['object_id'].isin(adopted_users).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d314f",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37eb0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilkinguliyev/opt/anaconda3/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:530: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamps\n",
    "users['creation_time'] = pd.to_datetime(users['creation_time'])\n",
    "users['last_session_creation_time'] = pd.to_datetime(users['last_session_creation_time'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f0a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['days_to_first_login'] = (users['last_session_creation_time'] - users['creation_time']).dt.days\n",
    "users['used_google_auth'] = (users['creation_source'] == 'SIGNUP_GOOGLE_AUTH').astype(int)\n",
    "users['invited'] = users['invited_by_user_id'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c07a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode creation_source\n",
    "users = pd.get_dummies(users, columns=['creation_source'], prefix='source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084fef0b",
   "metadata": {},
   "source": [
    "### Build a Model or Analyze Feature Impact\n",
    "\n",
    "For this project, we will use logistic regression because it is well-suited for binary classification tasks like predicting user adoption. It provides interpretable results, is quick to implement, and performs well on datasets with a limited number of features. Logistic regression also gives probability outputs, allowing us to not only classify users but also estimate how likely they are to become adopted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0411fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select features\n",
    "features = [\n",
    "    'opted_in_to_mailing_list',\n",
    "    'enabled_for_marketing_drip',\n",
    "    'used_google_auth',\n",
    "    'invited',\n",
    "    'days_to_first_login',\n",
    "] + [col for col in users.columns if col.startswith('source_')]\n",
    "\n",
    "X = users[features].fillna(0)\n",
    "y = users['is_adopted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "814d926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42556155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5aa927e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2586\n",
      "           1       0.90      0.86      0.88       414\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.94      0.92      0.93      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1c38f",
   "metadata": {},
   "source": [
    "##  Conclusion\n",
    "\n",
    "In this project, we aimed to identify the key factors that predict **user adoption**, defined as logging into the product on **three separate days within a seven-day period**. Using data from 12,000 users and their login activity, we engineered an \"adopted user\" label and built a predictive model to uncover patterns in user behavior and sign-up characteristics.\n",
    "\n",
    "Our final logistic regression model achieved an overall **accuracy of 97%**, with a precision of **90%** and recall of **86%** for predicting adopted users. This indicates the model performs well in correctly identifying users who are likely to become highly engaged with the product.\n",
    "\n",
    "###  Key Insights\n",
    "\n",
    "- Users who signed up via **organizational or personal invitations** were more likely to become adopted, suggesting **social or team-based onboarding** plays a significant role in engagement.\n",
    "- Sign-ups via **Google authentication** also had a positive effect, likely due to frictionless onboarding.\n",
    "- Users who opted into marketing communications showed slightly higher engagement, though the effect was modest.\n",
    "\n",
    "###  Opportunities for Improvement\n",
    "\n",
    "While the model performs well, we note a slight trade-off in **recall** for adopted users, meaning some engaged users are still missed. Future work could include:\n",
    "- Enhancing the model using more detailed behavioral features (e.g., session duration, actions taken),\n",
    "- Testing advanced models like **Random Forest** or **Gradient Boosting**,\n",
    "- Implementing **oversampling** or **threshold tuning** to capture more adopted users.\n",
    "\n",
    "---\n",
    "\n",
    "Ultimately, this analysis provides actionable insights to support **user onboarding strategies**, improve retention, and prioritize product features that align with early user success signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8abd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
